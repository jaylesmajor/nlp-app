{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This project has a large file size*\n",
    "\n",
    "Follow these instructions to use LFS on GitHub\n",
    "- git lfs install\n",
    "- git lfs track 'data/yelp-reviews.csv'\n",
    "- git add .gitattributes\n",
    "- git add data/yelp-reviews.csv\n",
    "- git commit -m 'Track large file with Git LFS'\n",
    "- git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\User\n",
      "[nltk_data]     1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\User\n",
      "[nltk_data]     1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\User\n",
      "[nltk_data]     1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(file_path):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "file_path = 'data/yelp-reviews.csv'\n",
    "df = load_data(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "def perform_eda(df):\n",
    "    missing_values = df.isna().sum()\n",
    "    \n",
    "    print(f'Number of missing values: {missing_values}')\n",
    "\n",
    "perform_eda(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "statistics = df.describe().T\n",
    "print('Summary Statistics')\n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark mode\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['stars'].value_counts().sort_index().plot(kind='bar', color='steelblue')\n",
    "\n",
    "plt.title('Distribution of Star Ratings for Sandbar', fontsize=16)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean text data\n",
    "def clean_data(df, text_column):\n",
    "    \n",
    "    # Remove missing values\n",
    "    df = df.dropna(subset=[text_column, 'stars'])\n",
    "    \n",
    "    # Normalize text data\n",
    "    df[text_column] = df[text_column].str.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    df[text_column] = df[text_column].apply(lambda x: re.sub(r'[^A-Za-z\\s]', '', x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = clean_data(df, text_column='text')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN/missing values in the text column\n",
    "missing_text = df['text'].isna().sum()\n",
    "print(f'Number of missing values in text column: {missing_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Engineering** (Tokenization and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('punkt_tab') if not downloaded\n",
    "\n",
    "# Initialize the stopwords object\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess text => tokens, remove stopwords and join tokens\n",
    "def preprocess_text_to_tokens(text):\n",
    "    \n",
    "    # Tokeinize text and filter stopwords\n",
    "    filtered_tokens = [\n",
    "        word for word in word_tokenize(text.lower()) if word not in stop_words\n",
    "    ]\n",
    "    \n",
    "    # Join the tokens into a string\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Create a tokens column and apply preprocessing to the text column and store the results in a tokens column\n",
    "df['tokens'] = df['text'].apply(preprocess_text_to_tokens)\n",
    "\n",
    "# Check transformations\n",
    "df[['text', 'tokens']].head() # return only the text and tokens columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the lemmatizer and stopwords object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess text => lemmas, remove stopwords and join lemmas\n",
    "def preprocess_text_to_lemmas(text):\n",
    "    \n",
    "    # Lemmatize text and filter stopwords\n",
    "    lemmas = [\n",
    "        lemmatizer.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stop_words\n",
    "    ]\n",
    "    \n",
    "    # Join the lemmas into a string\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "# Create a lemmas column and apply preprocessing to the text column and store the results in a lemmas column\n",
    "df['lemmas'] = df['text'].apply(preprocess_text_to_lemmas)\n",
    "\n",
    "# Check transformations\n",
    "df[['text', 'lemmas']].head() # return only the text and lemmas columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transformed dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Time Series Preprocessing**\n",
    "- Create a resampled dataset for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert review dates to datetime objects\n",
    "def convert_to_datetime(df, date_column):\n",
    "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce') # Convert to datetime, handle errors\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Set the date as the index\n",
    "def set_date_as_index(df, date_column):\n",
    "    df.set_index(date_column, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Resample the data by a specific time interval\n",
    "def resample_data(df, interval='ME'): # 'M' stands for months, 'D' stands for daily, 'W' for weekly\n",
    "    df_resampled = df.resample(interval).mean()\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index if 'date' is currently an index and not a column\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Then you can apply your original function to convert 'date' column to datetime\n",
    "df = convert_to_datetime(df, date_column='date')\n",
    "\n",
    "# After conversion, set 'date' back as the index\n",
    "df = set_date_as_index(df, date_column='date')\n",
    "\n",
    "def resample_numeric_data(df, interval='M'):\n",
    "    # Select only numeric columns for resampling\n",
    "    numeric_df = df.select_dtypes(include='number')\n",
    "    df_resampled = numeric_df.resample(interval).mean()\n",
    "    return df_resampled\n",
    "\n",
    "# Check if 'date' is already set as index\n",
    "if 'date' in df.columns:\n",
    "    df = set_date_as_index(df, date_column='date')\n",
    "\n",
    "# Resample numeric data only\n",
    "df_resampled = resample_numeric_data(df, interval='M')\n",
    "\n",
    "# Check resampled data\n",
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "output_path = 'data/reviews_processed_tsa.csv'\n",
    "df_resampled.to_csv(output_path)\n",
    "print(f'Processed dataframed saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataframe\n",
    "df_resampled = pd.read_csv('data/reviews_processed_tsa.csv', keep_default_na=False)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df_resampled.isna().sum()\n",
    "print(f'Number of missing values: {missing_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Time Series Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Annotating the hightest and lowest points\n",
    "max_value = df_resampled['stars'].max()\n",
    "min_value = df_resampled['stars'].min()\n",
    "max_date = df_resampled['stars'].idxmax()\n",
    "min_date = df_resampled['stars'].idxmin()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_resampled.index, df_resampled['stars'], color='skyblue')\n",
    "plt.title('Average Star Ratings Over Time', fontsize=16)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Average Star Rating')\n",
    "\n",
    "plt.annotate(f'Max {max_value:.2f}',\n",
    "             xy=(max_date, max_value),\n",
    "             xytext=(max_date, max_value + 0.05),\n",
    "             arrowprops=dict(facecolor='green', shrink=0.05))\n",
    "\n",
    "plt.annotate(f'Min {min_value:.2f}',\n",
    "             xy=(min_date, min_value),\n",
    "             xytext=(min_date, min_value + - 0.05),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 3 month-moving average\n",
    "df_resampled['3-month-MA'] = df_resampled['stars'].rolling(window=3).mean()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_resampled.index, df_resampled['stars'], label='Monthly Average', color='skyblue')\n",
    "plt.plot(df_resampled.index, df_resampled['3-month-MA'], label='3-Month Moving Average', color='violet')\n",
    "plt.title('Average Star Ratings Over Time with 3 Month Moving Average', fontsize=16)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Average Star Rating')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep Learning**\n",
    "- Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create sequences from the time series data\n",
    "def create_sequences(data, sequence_length):\n",
    "    \n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Loop\n",
    "    for start_index in range(len(data) - sequence_length):\n",
    "        end_index = start_index + sequence_length\n",
    "        sequence = data[start_index:end_index]\n",
    "        target = data[end_index]\n",
    "        \n",
    "        sequences.append(sequence)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Sequence length 3 for quarterly, 6 is semi-annual, 12 is for annual\n",
    "sequence_length = 3 # for 3 months or quarterly\n",
    "X, y = create_sequences(df_resampled['stars'].values, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model (Long Short Term Memory) Deep Learning Model\n",
    "\n",
    "common errors:\n",
    "- ModuleNotFoundError: No module named 'tensorflow'\n",
    "- `pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# def build_lstm_model(input_shape, units_first_layer, units_second_layer, dropout_first, dropout_second):\n",
    "    \n",
    "#     # Initialize model\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     # Add first layer with dropout\n",
    "#     model.add(LSTM(units=units_first_layer, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(dropout_first))\n",
    "    \n",
    "#     # Add second layer with dropout\n",
    "#     model.add(LSTM(units=units_second_layer, return_sequences=False))\n",
    "#     model.add(Dropout(dropout_second))\n",
    "    \n",
    "#     # Add output layer\n",
    "#     model.add(Dense(units=1))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Compile the model\n",
    "# def compile_model(model, optimizer, loss):\n",
    "#     model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define input shape\n",
    "# input_shape = (X_train.shape[1], 1)\n",
    "\n",
    "# # Build the model\n",
    "# model = build_lstm_model(input_shape, units_first_layer=100, units_second_layer=50, dropout_first=0.5, dropout_second=0.2)\n",
    "\n",
    "# # Compile the model\n",
    "# model = compile_model(model, optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.keras import TqdmCallback\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=100,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[TqdmCallback(verbose=1)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import matplotlib.pyplot as plt\n",
    "# # from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# # def evaluate_model(model, X_test, y_test):\n",
    "    \n",
    "# #     test_loss = model.evaluate(X_test, y_test)\n",
    "# #     print(f'Test Loss: {test_loss}')\n",
    "    \n",
    "# #     return test_loss\n",
    "\n",
    "# # def calculate_metrics(y_test, predictions):\n",
    "# #     mse = mean_squared_error(y_test, predictions)\n",
    "# #     mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "# #     print(f'Mean Squared Error: {mse}')\n",
    "# #     print(f'Mean Absolute Error: {mae}')\n",
    "    \n",
    "# #     return mse, mae\n",
    "\n",
    "# # def predict_and_evaluate(model, X_test, y_test):\n",
    "    \n",
    "# #     # Evaluate model\n",
    "# #     test_loss = evaluate_model(model, X_test, y_test)\n",
    "# #     predictions = model.predict(X_test)\n",
    "    \n",
    "# #     # Calculate metrics\n",
    "# #     mse, mae = calculate_metrics(y_test, predictions)\n",
    "    \n",
    "# #     return predictions, mse, mae\n",
    "\n",
    "# # predictions, mse, mae = predict_and_evaluate(model, X_test, y_test)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "#     test_loss = model.evaluate(X_test, y_test)\n",
    "#     print(f'Test Loss: {test_loss}')\n",
    "    \n",
    "#     return test_loss\n",
    "\n",
    "# def calculate_metrics(y_test, predictions):\n",
    "#     mse = mean_squared_error(y_test, predictions)\n",
    "#     mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "#     print(f'Mean Squared Error: {mse}')\n",
    "#     print(f'Mean Absolute Error: {mae}')\n",
    "    \n",
    "#     return mse, mae\n",
    "\n",
    "# def predict_and_evaluate(model, X_test, y_test):\n",
    "    \n",
    "#     # Evaluate model\n",
    "#     test_loss = evaluate_model(model, X_test, y_test)\n",
    "#     predictions = model.predict(X_test)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     mse, mae = calculate_metrics(y_test, predictions)\n",
    "    \n",
    "#     return predictions, mse, mae\n",
    "\n",
    "# predictions, mse, mae = predict_and_evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_training_and_predictions(history, y_test, predictions):\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "#     # Training and validation loss\n",
    "#     axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "#     axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "#     axes[0].set_title('Model Loss')\n",
    "#     axes[0].set_xlabel('Loss')\n",
    "#     axes[0].set_xlabel('Epoch')\n",
    "#     axes[0].legend()\n",
    "    \n",
    "#     # Prediction VS Actual Values\n",
    "#     axes[1].plot(y_test, label='Actual Values')\n",
    "#     axes[1].plot(predictions, label='Predicted Values')\n",
    "#     axes[1].set_title('Model Predictions VS Actual Values')\n",
    "#     axes[1].set_xlabel('Time')\n",
    "#     axes[1].set_xlabel('Star Rating')\n",
    "#     axes[1].legend()\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "# print('LSTM Model Performance')\n",
    "# plot_training_and_predictions(history, y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save('models/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon') # if not already downloaded\n",
    "\n",
    "# Initialize the VADER object\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply VADER to the text data\n",
    "def apply_vader(text):\n",
    "    \n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "# Create vader_scores and vader_compound columns\n",
    "df['vader_scores'] = df['text'].apply(apply_vader)\n",
    "df['vader_compound'] = df['vader_scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "# Convert compound score to sentiment labels\n",
    "def vader_sentiment_label(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "    \n",
    "df['vader_sentiment'] = df['vader_compound'].apply(vader_sentiment_label)\n",
    "\n",
    "# Map stars to true_label for evaluation\n",
    "def map_stars_to_sentiment(stars):\n",
    "    if stars >= 4:\n",
    "        return 'Positive'\n",
    "    elif stars < 3:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "    \n",
    "df['true_label'] = df['stars'].apply(map_stars_to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(df['true_label'], df['vader_sentiment'], labels=labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels)\n",
    "\n",
    "disp.plot(cmap='Purples')\n",
    "plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Vectorize text\n",
    "def vectorize_text(text_data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(text_data)\n",
    "    \n",
    "    return X, vectorizer\n",
    "\n",
    "# Create binary target based on star rating\n",
    "def prepare_target_variable(stars, threshold=4):\n",
    "    return stars >= threshold\n",
    "\n",
    "# Classifier model\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    nb_classifier = MultinomialNB()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    return nb_classifier\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model_nb(model, X_test, y_test):\n",
    "    test_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    return accuracy, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text\n",
    "X, vectorizer = vectorize_text(text_data=df['lemmas'])\n",
    "y = df['true_label']\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train model\n",
    "nb_classifier = train_naive_bayes(X_train, y_train)\n",
    "accuracy, test_pred = evaluate_model_nb(nb_classifier, X_test, y_test)\n",
    "\n",
    "print(f'Naive Bayes Accuracy with TF-IDF (Multi-Class): {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, test_pred, labels=labels)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, test_pred, labels=labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels)\n",
    "disp.plot(cmap='Purples')\n",
    "plt.title('Sentiment Analysis with Naive Bayes and TF-IDF (Multi-Class)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
